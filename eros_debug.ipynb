{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eros norm:\n",
    "$$\n",
    "EROS(\\mathbf{A,B},w) = \\sum_{i=1}^n w_i\\cdot|<a_i,b_i>|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data_no_bool.json\").T\n",
    "df.head()\n",
    "\n",
    "#from sklearn.utils import shuffle\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 0\n",
    "\n",
    "# Shuffle the dataframe\n",
    "shuffled_df = sk.utils.shuffle(df, random_state=seed)\n",
    "shuffled_df.head()\n",
    "\n",
    "from utils import extract_matrix\n",
    "# Create the matrix version\n",
    "shuffled_df.time_series = shuffled_df.time_series.apply(extract_matrix)\n",
    "shuffled_df[\"shape\"] = shuffled_df.time_series.apply(lambda x: x.shape)\n",
    "shuffled_df.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shuffled_df['time_series'], shuffled_df['label'], train_size=.75, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_S_matrix(ts_series:pd.Series, means:np.array, vars:np.array) -> tuple:\n",
    "    \"\"\"function to compute the S matrix of shape n x N (n = number of predictors, N = number of examples). \n",
    "    Such matrix will be used to compute\n",
    "    the weight vector needed by Eros norm\n",
    "\n",
    "    Args:\n",
    "        -ts_series (pd.Series): Series containing the dataset of time series.\n",
    "        Each entry is a list of vectors. \n",
    "        Each vector is a component of the i-th time series\n",
    "        -means (np.array): array containing the means of the features in order to scale them\n",
    "        -vars (np.array): array containing the vars of the features in order to scale them\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, list]: returns the matrix S and the list of\n",
    "        right eigenvectors matrices computed for each time series\n",
    "    \"\"\"\n",
    "    s_matrix = np.zeros(shape=(len(ts_series), ts_series.iloc[0].shape[-1]))\n",
    "    v_list = [] # list of right eigenvector matrix\n",
    "    for i in range(len(ts_series)):\n",
    "        ts = ts_series.iloc[i] # time x predictors\n",
    "        #The matrix S will be nxN where n is the predictor dimension and N is the number of time-series examples.\n",
    "        #Hence, we will use the transpose to compute the covariance matrix.\n",
    "        ts = (ts - means)/vars\n",
    "        ts = ts.T # predictors x time\n",
    "        #Compute the covariance matrix of the i-th example of the dataset\n",
    "        #cov_ts = np.corrcoef(ts)\n",
    "        cov_ts = np.cov(ts)\n",
    "        # Compute the SVD of the covariance matrix\n",
    "        u, s, v_t = np.linalg.svd(cov_ts)\n",
    "        s_matrix[i] = s\n",
    "        v_list.append(v_t.T)\n",
    "    return s_matrix.T, v_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix = np.vstack(X_train)\n",
    "means_train = np.mean(X_train_matrix, axis=0)\n",
    "vars_train = np.var(X_train_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, v_list_train = compute_S_matrix(X_train, means_train, vars_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, v_list_test = compute_S_matrix(X_test, means_train, vars_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight_vector(S:np.ndarray, aggregation:str='mean', algorithm:int=1) -> np.array:\n",
    "    \"\"\"compute the weight vector used in the computation of Eros norm\n",
    "\n",
    "    Args:\n",
    "        S (np.ndarray): matrix containing eigenvalues of each predictor\n",
    "        aggregation (str, optional): aggregation function to use. Defaults to 'mean'.\n",
    "        algorithm(int): choose the algorithm to use to compute weight vector.\n",
    "        - Algorithm 1: do not normalize rows of the S matrix. Perform directly the computation of w\n",
    "        - Algorithm 2: first normalize rows of the S matrix and then compute w.\n",
    "    Returns:\n",
    "        np.array: return the normalized weight vector\n",
    "    \"\"\"\n",
    "    n = S.shape[0] # number of predictors\n",
    "    if (algorithm == 2):\n",
    "        # first normalize each eigenvalues\n",
    "        S = S/np.sum(S, axis=0)\n",
    "    if (aggregation == 'mean'):\n",
    "        w = np.mean(S, axis=-1)\n",
    "    elif (aggregation == 'min'):\n",
    "        w = np.min(S, axis=-1)\n",
    "    elif (aggregation == 'max'):\n",
    "        w = np.max(S, axis=-1)\n",
    "    return w/np.sum(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = compute_weight_vector(S, algorithm=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eros_norm(weight_vector:np.array, A:np.array, B:np.array):\n",
    "    \"\"\"compute eros norm\n",
    "\n",
    "    Args:\n",
    "        weight_vector (np.array): weight vector\n",
    "        A (np.array): time_series_1\n",
    "        B (np.array): time_series_2\n",
    "\n",
    "    Returns:\n",
    "        float: distance between the 2 time series. Bounded in (0,1]\n",
    "    \"\"\"\n",
    "    # since we want to use a_i and b_i which \n",
    "    # are the orthonormal column vectors of A and B,\n",
    "    # we decide to transpose A and B\n",
    "    A = A.T\n",
    "    B = B.T\n",
    "    n = A.shape[0] # number of predictors\n",
    "\n",
    "    \n",
    "    eros = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        eros += weight_vector[i]*np.abs(np.dot(A[i], B[i]))\n",
    "    return eros\n",
    "\n",
    "def compute_kernel_matrix(num_examples:int, weight_vector:np.array, v_list:list) -> np.array:\n",
    "    \"\"\"compute the kernel matrix to be used in PCA\n",
    "\n",
    "    Args:\n",
    "        num_examples (int): number of examples in the dataset\n",
    "        weight_vector (np.array): weight vector \n",
    "        v_t_list (list[np.array]): list of right eigenvector matrices\n",
    "\n",
    "    Returns:\n",
    "        np.array: kernel matrix with pairwise eros norm\n",
    "    \"\"\"\n",
    "    N = num_examples\n",
    "    K_eros = np.zeros(shape=(N,N))\n",
    "\n",
    "    for i in range(N):\n",
    "        j = 0\n",
    "        while (j <= i):\n",
    "            K_eros[i,j] = eros_norm(weight_vector, v_list[i], v_list[j])\n",
    "            if (i != j): \n",
    "                K_eros[j,i] = K_eros[i,j]\n",
    "            j += 1\n",
    "\n",
    "    # check whether the kernel matrix is positive semi definite (PSD) or not\n",
    "    is_psd = np.all(np.linalg.eigvals(K_eros) >= 0)\n",
    "    #is_psd = True\n",
    "    print(np.min(np.linalg.eigvals(K_eros)))\n",
    "    threshold = 1e-10\n",
    "    # if not PSD, add to the diagonal the minimal value among eigenvalues of K_eros\n",
    "    if is_psd == False:\n",
    "        delta = np.min(np.linalg.eigvals(K_eros))\n",
    "        delta_ary = [np.abs(delta) + threshold for _ in range(K_eros.shape[0])]\n",
    "        K_eros += np.diag(delta_ary)\n",
    "    is_psd = np.all(np.linalg.eigvals(K_eros) >= 0)\n",
    "    if is_psd == True:\n",
    "        print(\"now PSD\")\n",
    "    else:\n",
    "        print(\"not PSD\")\n",
    "    return K_eros\n",
    "\n",
    "def perform_PCA(num_examples:int, weight_vector:np.array, v_list:list) -> tuple:\n",
    "    \"\"\"extract principal components in the feature space\n",
    "\n",
    "    Args:\n",
    "        num_examples (int): number of examples in the dataset\n",
    "        weight_vector (np.array): weight vector \n",
    "        v_t_list (list[np.array]): list of right eigenvector matrices\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.array]:\n",
    "        - K_eros matrix\n",
    "        - eigenvectors (principal components) of the feature space\n",
    "    \"\"\"\n",
    "    K_eros = compute_kernel_matrix(num_examples, weight_vector, v_list)\n",
    "    O = np.ones(shape=(num_examples,num_examples))\n",
    "    O *= 1/num_examples\n",
    "    K_eros_mc = K_eros - O@K_eros - K_eros@O + O@K_eros@O # K_eros mean centered\n",
    "    is_psd = np.all(np.linalg.eigvals(K_eros_mc) >= 0)\n",
    "    print(f\"K eros mean centered is {'not ' if not is_psd else ''}PSD\")\n",
    "    \n",
    "    ####### added #######\n",
    "    threshold = 10e-10\n",
    "    if is_psd == False:\n",
    "        delta = np.min(np.linalg.eigvals(K_eros_mc))\n",
    "        delta_ary = [np.abs(delta) + threshold for _ in range(K_eros_mc.shape[0])]\n",
    "        K_eros_mc += np.diag(delta_ary)\n",
    "    is_psd = np.all(np.linalg.eigvals(K_eros_mc) >= 0)\n",
    "    print(f\"K eros mean centered is {'not ' if not is_psd else ''}PSD\")\n",
    "    ####### added #######\n",
    "    \n",
    "    \n",
    "    eig_vals, eig_vecs = np.linalg.eig(K_eros_mc)\n",
    "    #return K_eros, eig_vecs, eig_vals\n",
    "    \n",
    "    ####### added #######\n",
    "    return K_eros_mc, eig_vecs, eig_vals\n",
    "    ####### added #######\n",
    "     \n",
    "\n",
    "def project_test_data(num_training_examples:int, num_test_examples:int, weight_vector:np.array, v_list_train:list, v_list_test:list, K_eros_train:np.ndarray, V:np.ndarray) -> tuple:\n",
    "    \"\"\"compute the K eros test kernel matrix used to project test data\n",
    "\n",
    "    Args:\n",
    "        num_examples_train (int): number of examples in the training dataset\n",
    "        num_examples_test (int): number of examples in the test dataset\n",
    "        weight_vector (np.array): weight vector \n",
    "        v_list_train (list[np.array]): list of right eigenvector matrices of the training dataset\n",
    "        v_list_test (list[np.array]): list of right eigenvector matrices of the test dataset\n",
    "\n",
    "    Returns:\n",
    "        np.array: kernel matrix with pairwise eros norm\n",
    "    \"\"\"\n",
    "    N_train = num_training_examples\n",
    "    N_test = num_test_examples\n",
    "    K_eros_test = np.zeros(shape=(N_test,N_train))\n",
    "\n",
    "    for i in range(N_test):\n",
    "        for j in range(N_train):\n",
    "            K_eros_test[i,j] = eros_norm(weight_vector, v_list_test[i], v_list_train[j])\n",
    "    \n",
    "    O_test = np.ones(shape=(N_test, N_train))*(1/N_train)\n",
    "    O_train = np.ones(shape=(N_train, N_train))*(1/N_train)\n",
    "\n",
    "    K_eros_test_mc = K_eros_test - O_test@K_eros_train - K_eros_test@O_train + O_test@K_eros_train@O_train\n",
    "\n",
    "    Y = K_eros_test_mc @ V\n",
    "    \n",
    "    # return Y, K_eros_test\n",
    "    return Y, K_eros_test_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.108689452828127\n",
      "now PSD\n",
      "K eros mean centered is PSD\n",
      "K eros mean centered is PSD\n"
     ]
    }
   ],
   "source": [
    "# K_eros_train, V, eig_vals = perform_PCA(len(X_train), weight_vector=w, v_list=v_list_train)\n",
    "K_eros_train_mc, V, eig_vals = perform_PCA(len(X_train), weight_vector=w, v_list=v_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y, K_eros_test = project_test_data(len(X_train), len(X_test), w, v_list_train, v_list_test, K_eros_train, V)\n",
    "Y, K_eros_test_mc = project_test_data(len(X_train), len(X_test), w, v_list_train, v_list_test, K_eros_train_mc, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the $i$-th MTS item in the test set is represented as features (length = num examples in the training set) in the $i$-th row of $\\mathbf{Y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 223)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova_train = y_train.to_numpy().astype('int')\n",
    "prova_test = y_test.to_numpy().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig('rl_eros_mean_centered.log', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations...:   1%|          | 29/3888 [00:00<00:26, 143.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.14666666666666667, best combination: kernel:linear, C=1e-05, gamma=1e-05, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations...:  12%|█▏        | 453/3888 [00:03<00:26, 130.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.28, best combination: kernel:linear, C=0.1, gamma=1e-05, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations...:  15%|█▍        | 564/3888 [00:03<00:25, 129.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.52, best combination: kernel:linear, C=1, gamma=1e-05, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations...:  91%|█████████ | 3537/3888 [00:29<00:02, 126.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.5333333333333333, best combination: kernel:sigmoid, C=1, gamma=1, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations...: 100%|██████████| 3888/3888 [00:31<00:00, 121.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy score: 0.5333333333333333, best combination: kernel:sigmoid, C=1, gamma=1, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "# MEAN CENTERED\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "best_acc_score = 0\n",
    "best_combination = ''\n",
    "params = [['linear', 'poly', 'rbf', 'sigmoid'], [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10], [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],[15,16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 30]]\n",
    "params_comb = list(itertools.product(*params))\n",
    "for params in tqdm(params_comb, desc='calculating diff params combinations...'):\n",
    "    svc = SVC(kernel=params[0], C=params[1], gamma = params[2], degree= params[3])\n",
    "    princ_components = V#[:, :51]\n",
    "    svc.fit(princ_components, prova_train)\n",
    "    test_princ_components = Y#[:, :51]\n",
    "    predictions = svc.predict(test_princ_components)\n",
    "    res = accuracy_score(prova_test, predictions)\n",
    "    if res > best_acc_score:\n",
    "        best_acc_score = res\n",
    "        best_combination = f'kernel:{params[0]}, C={params[1]}, gamma={params[2]}, degree={params[3]}.'\n",
    "        logging.info(f'[EROS-MEAN-CENTERED] found new best acc score! {best_acc_score}, best combination: {best_combination}')\n",
    "        print(f'found new best acc score! {best_acc_score}, best combination: {best_combination}')\n",
    "print(f'best accuracy score: {best_acc_score}, best combination: {best_combination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "391ddcc66a8b67209ee4ca14a5da0cf1073041a687facbd61882e6753a3822ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
